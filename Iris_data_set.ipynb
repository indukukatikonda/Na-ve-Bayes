{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P__QSg8TfSbz",
        "outputId": "faeca689-5ac2-4cdb-e80a-691f120db4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  2 11]]\n",
            "Accuracy: 0.9555555555555556\n",
            "Error Rate: 0.0444444444444444\n",
            "Precision: 0.9614814814814815\n",
            "Recall: 0.9555555555555556\n",
            "F1 Score: 0.9552910052910052\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the iris dataset from the CSV file\n",
        "df = pd.read_csv('/content/iris.csv')  # Replace this path with the actual path if needed\n",
        "\n",
        "# Inspect the data to understand its structure\n",
        "print(df.head())  # Check the first few rows to understand column names and data structure\n",
        "\n",
        "# Assuming the 'Species' column is the target, and the rest are features\n",
        "X = df.drop(\"Species\", axis=1)  # Replace \"Species\" with the actual target column name if it's different\n",
        "y = df[\"Species\"]\n",
        "\n",
        "# Encoding categorical labels if needed\n",
        "y = pd.factorize(y)[0]  # Convert species names to numerical labels if needed\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initializing and training the Naive Bayes classifier\n",
        "model = CategoricalNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculating evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "error_rate = 1 - accuracy\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Outputting the results\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Error Rate:\", error_rate)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    }
  ]
}